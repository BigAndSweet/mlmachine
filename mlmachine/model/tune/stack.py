import ast

import numpy as np
from collections import OrderedDict

from sklearn import model_selection
import sklearn.decomposition as decomposition
import sklearn.discriminant_analysis as discriminant_analysis
import sklearn.ensemble as ensemble
import sklearn.gaussian_process as gaussian_process
import sklearn.linear_model as linear_model
import sklearn.kernel_ridge as kernel_ridge
import sklearn.naive_bayes as naive_bayes
import sklearn.neighbors as neighbors
import sklearn.svm as svm
import sklearn.tree as tree

import xgboost
import lightgbm
import catboost


def powerGridModelBuilder(self, results, modelIx):
    """
    Documentation:
        Description:
            Model building utility to be used with powerGridSearch summary results. Returns 
            estimator and dictionary of 'parameter : value' pairs to be passed as kwarg
            to model. Used to efficiently reinstantiated specific models.
        Parameters:
            results : Pandas DataFrame
                DataFrame containing score summary generated by PowerGridSearcher.
            modelIx : int
                Row index of specific model summarized in results DataFrame.
        Returns:
            estimator : sklearn model
                sklearn model object.
            params.to_dict() : dictionary
                Dictionary containing model parameters value.
    """
    estimator = results.loc[modelIx][0]
    params = results.loc[modelIx][5:].dropna(axis=0)

    # convert floats that are effectively ints to ints
    for ix in params.index:
        if not isinstance(params[ix], str):
            if int(params[ix]) == params[ix] and isinstance(params[ix], float):
                params[ix] = params[ix].astype(np.int64)

    return estimator, params.to_dict()


def bayesOptimModelBuilder(self, resultsRaw, estimator, iteration):
    """
    Documentation:
        Description:
            Extract parameter dictionary from the input resultsRaw DataFrame
        Parameters:
            resultsRaw : Pandas DataFrame
                Pandas DataFrame summarzing models and associated parameters.
            estimator : string
                Subset resultDf based on this estimator.
            iteration : int
                Number for identifying specific model parameters to capture from resultsRaw.
        Returns:
            params : dictionary
                Return dictionary containing 'parameter : value' pairs for the the specified
                model and iteration.
    """
    params = resultsRaw[
        (resultsRaw["estimator"] == estimator) & (resultsRaw["iteration"] == iteration)
    ]["params"].values[0]
    return ast.literal_eval(params)


class SklearnHelper:
    """
    Documentation:
        Description:
            Helper class for instantiating an input model type with a provided
            parameter set.
        Parameters:
            model : sklearn model
                Model to instantiate.
            seed : int
                Random number seed.
            params : dictionary
                Dictionary containing 'parameter : value' pairs.
            nJobs : int, default = 2
                Number of works to use when training the model. This parameter will be 
                ignored if the model does not have this parameter.
        Returns:
            model : model object
                Model instantiated using parameter set. Model possesses train, predict, fit
                and feature_importances methods.
    """

    def __init__(self, model, seed=0, params=None, nJobs=2):
        # ensure that models which do not have an n_jobs parameter do not have that parameter
        # added to the parameter kwargs
        if model not in [
            ensemble.GradientBoostingClassifier,
            ensemble.GradientBoostingRegressor,
            ensemble.AdaBoostClassifier,
            ensemble.AdaBoostRegressor,
            naive_bayes.BernoulliNB,
            naive_bayes.GaussianNB,
            svm.SVC,
        ]:
            params["n_jobs"] = nJobs
        self.model = model(**params)

    def train(self, XTrain, yTrain):
        self.model.fit(XTrain, yTrain)

    def predict(self, x):
        return self.model.predict(x)

    def fit(self, x, y):
        return self.model.fit(x, y)

    def feature_importances(self, x, y):
        return self.model.fit(x, y).feature_importances_


def oofGenerator(self, model, XTrain, yTrain, XValid, nFolds=10):
    """
    Documentation:
        Description:
            Generates out-of-fold (oof) predictions using provided model, training dataset
            and corresponding labels, and a validation dataset.
        Parameters:
            model : sklearn model or pipeline
                Model to be fit.
            XTrain : array
                Training dataset.
            yTrain : array
                Training dataset labels.
            XValid : array
                Validation dataset.
            nFolds : int, default = 10
                Number of folds for performing cross-validation. Function will generate this
                many sets of out-of-fold predictions.
        Returns:
            oofTrain : array
                Array containing observation data to be passed to the meta-learner. oofTrain 
                is updated throughout the cross-validation process with observations that are 
                identified as test observations in each fold.
            oofValid : array
                Array containing average of all out-of-fold predictions. To be passed to the
                meta-learner.
    """
    # row counts
    ntrain = XTrain.shape[0]
    nvalid = XValid.shape[0]

    # kfold train/test index generator
    kf = model_selection.KFold(n_splits=nFolds)

    # create shell arrays for holding results
    oofTrain = np.zeros((ntrain,))
    oofValid = np.zeros((nvalid,))
    oofValidScores = np.empty((nFolds, nvalid))

    # iterate through all kfolds to train model, capture scores
    for i, (trainIx, testIx) in enumerate(kf.split(XTrain)):
        # set train/test observations based on KFold indices
        XTrainFold = XTrain[trainIx]
        yTrainFold = yTrain[trainIx]
        XTestFold = XTrain[testIx]

        # train model based on training variables and labels
        model.train(XTrainFold, yTrainFold)

        # update segment of oofTrain where indices match the indices of the observations
        # used as test observations. These are the "out of fold" observations that we are not
        # considered in the training phase of the model
        oofTrain[testIx] = model.predict(XTestFold)

        # generate predictions using entire validation dataset, otherwise unused up to this point
        # and capture predictions for each folds
        oofValidScores[i, :] = model.predict(XValid)

    # determine average score of validation predictions
    oofValid[:] = oofValidScores.mean(axis=0)
    return oofTrain.reshape(-1, 1), oofValid.reshape(-1, 1)


def modelStacker(self, models, resultsRaw, XTrain, yTrain, XValid, nFolds, nJobs):
    """
    Documentation:
        Description:
            Stacking helper.
        Parameters:
            models : dictionary
                Dictionary of 'X : y' pairs  to be fit.
            XTrain : array
                Training dataset.
            yTrain : array
                Labels for training dataset.
            XValid : array
                Validation dataset.
            nFolkds : int
                Number of folds for performing cross-validation. Function will generate this
                many sets of out-of-fold predictions.
            nJobs : int
                Number of works to use when training the model. This parameter will be 
                ignored if the model does not have this parameter.
        Returns:
            oofTrain : array
                Out-of-fold training data observations.
            oofValid : array
                Out-of-fold validation data observations.
            columns : list
                List containing estimator names.
    """
    columns = []
    # iterate through estimators
    for estimator in models.keys():
        # iterate through parameter set for estimator
        for iteration in models[estimator]:
            print(estimator + " " + str(iteration))
            params = self.bayesOptimModelBuilder(
                resultsRaw=resultsRaw, estimator=estimator, iteration=iteration
            )
            columns.append(estimator + "_" + str(iteration))

            model = SklearnHelper(model=eval(estimator), params=params, nJobs=nJobs)
            oofTrainModel, oofValidModel = self.oofGenerator(
                model=model, XTrain=XTrain, yTrain=yTrain, XValid=XValid, nFolds=nFolds
            )
            try:
                oofTrain = np.hstack((oofTrain, oofTrainModel))
                oofValid = np.hstack((oofValid, oofValidModel))
            except NameError:
                oofTrain = oofTrainModel
                oofValid = oofValidModel
    return oofTrain, oofValid, columns
